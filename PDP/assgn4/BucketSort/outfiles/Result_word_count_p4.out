SLURM Environment Variables:
Job ID = 3096335
Job Name = word_count
Job Node List = k08n41s[01-02]
Number of Nodes = 2
Tasks per node = 8
CPUs per task = 
/scratch/jobid = /scratch/3096335
Submit Host = k07n14
Submit Directory = /ifs/user/balasesh/assgn4/Test


Currently Loaded Modulefiles:
  1) null                          4) hadoop/0.20.1
  2) modules                       5) myhadoop/0.2a/hadoop-0.20.1
  3) java/j2sdk/1.6.0_22
MY_HADOOP_HOME=/util/myhadoop/myHadoop-0.2a
HADOOP_HOME=/util/hadoop/hadoop-0.20.1
MyHadoop config directory=/ifs/user/balasesh/assgn4/Test/config
Set up the configurations for myHadoop
Number of nodes in nodelist=2
Number of Hadoop nodes requested: 2
Generation Hadoop configuration in directory: /ifs/user/balasesh/assgn4/Test/config
Not persisting HDFS state
Received 2 nodes from PBS
Master is: k08n41s01
Configuring node: k08n41s01
rm -rf /scratch/hadoop-balasesh/log; mkdir -p /scratch/hadoop-balasesh/log
rm -rf /scratch/hadoop-balasesh/data; mkdir -p /scratch/hadoop-balasesh/data
Configuring node: k08n41s02
rm -rf /scratch/hadoop-balasesh/log; mkdir -p /scratch/hadoop-balasesh/log
rm -rf /scratch/hadoop-balasesh/data; mkdir -p /scratch/hadoop-balasesh/data

Format HDFS
14/12/07 15:22:40 INFO namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = k08n41s01/10.111.8.41
STARTUP_MSG:   args = [-format]
STARTUP_MSG:   version = 0.20.1
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/common/tags/release-0.20.1-rc1 -r 810220; compiled by 'oom' on Tue Sep  1 20:55:56 UTC 2009
************************************************************/
14/12/07 15:22:41 INFO namenode.FSNamesystem: fsOwner=balasesh,cse603f14,u2
14/12/07 15:22:41 INFO namenode.FSNamesystem: supergroup=supergroup
14/12/07 15:22:41 INFO namenode.FSNamesystem: isPermissionEnabled=true
14/12/07 15:22:41 INFO common.Storage: Image file of size 98 saved in 0 seconds.
14/12/07 15:22:41 INFO common.Storage: Storage directory /scratch/hadoop-balasesh/data/dfs/name has been successfully formatted.
14/12/07 15:22:41 INFO namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at k08n41s01/10.111.8.41
************************************************************/

start dfs
starting namenode, logging to /scratch/hadoop-balasesh/log/hadoop-balasesh_k08n41s01-namenode-k08n41s01.out
k08n41s02: starting datanode, logging to /scratch/hadoop-balasesh/log/hadoop-balasesh_k08n41s02-datanode-k08n41s02.out
k08n41s01: starting datanode, logging to /scratch/hadoop-balasesh/log/hadoop-balasesh_k08n41s01-datanode-k08n41s01.out
k08n41s01: starting secondarynamenode, logging to /scratch/hadoop-balasesh/log/hadoop-balasesh_k08n41s01-secondarynamenode-k08n41s01.out

start jobtracker (mapred)
starting jobtracker, logging to /scratch/hadoop-balasesh/log/hadoop-balasesh_k08n41s01-jobtracker-k08n41s01.out
k08n41s01: starting tasktracker, logging to /scratch/hadoop-balasesh/log/hadoop-balasesh_k08n41s01-tasktracker-k08n41s01.out
k08n41s02: starting tasktracker, logging to /scratch/hadoop-balasesh/log/hadoop-balasesh_k08n41s02-tasktracker-k08n41s02.out

copy file to dfs
ls files in dfs
ls: Cannot access .: No such file or directory.

run computation
14/12/07 15:23:34 WARN mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
14/12/07 15:23:34 INFO input.FileInputFormat: Total input paths to process : 1
14/12/07 15:23:34 INFO mapred.JobClient: Running job: job_201412071523_0001
14/12/07 15:23:35 INFO mapred.JobClient:  map 0% reduce 0%
14/12/07 15:23:42 INFO mapred.JobClient:  map 100% reduce 0%
14/12/07 15:23:54 INFO mapred.JobClient:  map 100% reduce 100%
14/12/07 15:23:56 INFO mapred.JobClient: Job complete: job_201412071523_0001
14/12/07 15:23:56 INFO mapred.JobClient: Counters: 17
14/12/07 15:23:56 INFO mapred.JobClient:   Job Counters 
14/12/07 15:23:56 INFO mapred.JobClient:     Launched reduce tasks=1
14/12/07 15:23:56 INFO mapred.JobClient:     Launched map tasks=1
14/12/07 15:23:56 INFO mapred.JobClient:     Data-local map tasks=1
14/12/07 15:23:56 INFO mapred.JobClient:   FileSystemCounters
14/12/07 15:23:56 INFO mapred.JobClient:     FILE_BYTES_READ=100006
14/12/07 15:23:56 INFO mapred.JobClient:     HDFS_BYTES_READ=130000
14/12/07 15:23:56 INFO mapred.JobClient:     FILE_BYTES_WRITTEN=200044
14/12/07 15:23:56 INFO mapred.JobClient:     HDFS_BYTES_WRITTEN=105693
14/12/07 15:23:56 INFO mapred.JobClient:   Map-Reduce Framework
14/12/07 15:23:56 INFO mapred.JobClient:     Reduce input groups=0
14/12/07 15:23:56 INFO mapred.JobClient:     Combine output records=0
14/12/07 15:23:56 INFO mapred.JobClient:     Map input records=1
14/12/07 15:23:56 INFO mapred.JobClient:     Reduce shuffle bytes=0
14/12/07 15:23:56 INFO mapred.JobClient:     Reduce output records=0
14/12/07 15:23:56 INFO mapred.JobClient:     Spilled Records=20000
14/12/07 15:23:56 INFO mapred.JobClient:     Map output bytes=80000
14/12/07 15:23:56 INFO mapred.JobClient:     Combine input records=0
14/12/07 15:23:56 INFO mapred.JobClient:     Map output records=10000
14/12/07 15:23:56 INFO mapred.JobClient:     Reduce input records=10000
The time is: 22
ls files in dfs
Found 2 items
drwxr-xr-x   - balasesh supergroup          0 2014-12-07 15:23 /user/balasesh/output_wordcount/_logs
-rw-r--r--   1 balasesh supergroup     105693 2014-12-07 15:23 /user/balasesh/output_wordcount/part-r-00000
Copy output from HDFS to local directory
stop jobtracker (mapred)
stopping jobtracker
k08n41s02: stopping tasktracker
k08n41s01: stopping tasktracker
stop dfs
stopping namenode
k08n41s01: stopping datanode
k08n41s02: stopping datanode
k08n41s01: stopping secondarynamenode
Clean up
Number of Hadoop nodes specified by user: 2
Received 2 nodes from PBS
Clean up node: k08n41s01
rm -rf /scratch/hadoop-balasesh/data /scratch/hadoop-balasesh/log
Clean up node: k08n41s02
rm -rf /scratch/hadoop-balasesh/data /scratch/hadoop-balasesh/log

