SLURM Environment Variables:
Job ID = 3096505
Job Name = mahout_nb
Job Node List = d15n[32,34]
Number of Nodes = 2
Tasks per node = 2
CPUs per task = 
/scratch/jobid = /scratch/3096505
Submit Host = k07n14
Submit Directory = /ifs/user/balasesh/assgn4/mahout


Currently Loaded Modulefiles:
  1) null                          4) hadoop/0.20.1
  2) modules                       5) myhadoop/0.2a/hadoop-0.20.1
  3) java/j2sdk/1.6.0_22           6) mahout/0.8
MY_HADOOP_HOME=/util/myhadoop/myHadoop-0.2a
HADOOP_HOME=/util/hadoop/hadoop-0.20.1
MAHOUT_HOME=/util/mahout/mahout-distribution-0.8
MyHadoop config directory=/ifs/user/balasesh/assgn4/mahout/config
Set up the configurations for myHadoop
Number of nodes in nodelist=2
Number of Hadoop nodes requested: 2
Generation Hadoop configuration in directory: /ifs/user/balasesh/assgn4/mahout/config
Not persisting HDFS state
Received 2 nodes from PBS
Master is: d15n32
Configuring node: d15n32
rm -rf /scratch/hadoop-balasesh/log; mkdir -p /scratch/hadoop-balasesh/log
rm -rf /scratch/hadoop-balasesh/data; mkdir -p /scratch/hadoop-balasesh/data
Configuring node: d15n34
rm -rf /scratch/hadoop-balasesh/log; mkdir -p /scratch/hadoop-balasesh/log
rm -rf /scratch/hadoop-balasesh/data; mkdir -p /scratch/hadoop-balasesh/data

Format HDFS
14/12/07 16:22:37 INFO namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = d15n32/10.104.15.32
STARTUP_MSG:   args = [-format]
STARTUP_MSG:   version = 0.20.1
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/common/tags/release-0.20.1-rc1 -r 810220; compiled by 'oom' on Tue Sep  1 20:55:56 UTC 2009
************************************************************/
14/12/07 16:22:37 INFO namenode.FSNamesystem: fsOwner=balasesh,cse603f14,u2
14/12/07 16:22:37 INFO namenode.FSNamesystem: supergroup=supergroup
14/12/07 16:22:37 INFO namenode.FSNamesystem: isPermissionEnabled=true
14/12/07 16:22:37 INFO common.Storage: Image file of size 98 saved in 0 seconds.
14/12/07 16:22:37 INFO common.Storage: Storage directory /scratch/hadoop-balasesh/data/dfs/name has been successfully formatted.
14/12/07 16:22:37 INFO namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at d15n32/10.104.15.32
************************************************************/

start dfs
starting namenode, logging to /scratch/hadoop-balasesh/log/hadoop-balasesh_d15n32-namenode-d15n32.out
d15n34: starting datanode, logging to /scratch/hadoop-balasesh/log/hadoop-balasesh_d15n34-datanode-d15n34.out
d15n32: starting datanode, logging to /scratch/hadoop-balasesh/log/hadoop-balasesh_d15n32-datanode-d15n32.out
d15n32: starting secondarynamenode, logging to /scratch/hadoop-balasesh/log/hadoop-balasesh_d15n32-secondarynamenode-d15n32.out

start jobtracker (mapred)
starting jobtracker, logging to /scratch/hadoop-balasesh/log/hadoop-balasesh_d15n32-jobtracker-d15n32.out
d15n32: starting tasktracker, logging to /scratch/hadoop-balasesh/log/hadoop-balasesh_d15n32-tasktracker-d15n32.out
d15n34: starting tasktracker, logging to /scratch/hadoop-balasesh/log/hadoop-balasesh_d15n34-tasktracker-d15n34.out

------- make directory ----
------- copy training data to dfs---
------- list files in dfs---
Found 1 items
drwxr-xr-x   - balasesh supergroup          0 2014-12-07 16:23 /data/tweets-seq
-------Using mahout to transform the training data into vectors using tfidf weights ---
CLASSPATH with MAHOUT=:/util/mahout/mahout-distribution-0.8/src/conf
MAHOUT_LOCAL is not set; adding HADOOP_CONF_DIR to classpath.
CLASSPATH with HADOOP=:/util/mahout/mahout-distribution-0.8/src/conf:/ifs/user/balasesh/assgn4/mahout/config
CLASSPATH with JAVA=:/util/mahout/mahout-distribution-0.8/src/conf:/ifs/user/balasesh/assgn4/mahout/config:/util/java/jdk1.6.0_22//lib/tools.jar
Running on hadoop, using /util/hadoop/hadoop-0.20.1/bin/hadoop and HADOOP_CONF_DIR=/ifs/user/balasesh/assgn4/mahout/config
MAHOUT-JOB: /util/mahout/mahout-distribution-0.8/examples/target/mahout-examples-0.8-job.jar
14/12/07 16:23:34 INFO vectorizer.SparseVectorsFromSequenceFiles: Maximum n-gram size is: 1
14/12/07 16:23:34 INFO vectorizer.SparseVectorsFromSequenceFiles: Minimum LLR value: 1.0
14/12/07 16:23:34 INFO vectorizer.SparseVectorsFromSequenceFiles: Number of reduce tasks: 1
14/12/07 16:23:34 INFO vectorizer.SparseVectorsFromSequenceFiles: Tokenizing documents in /data/tweets-seq
14/12/07 16:23:35 INFO input.FileInputFormat: Total input paths to process : 1
14/12/07 16:23:35 INFO mapred.JobClient: Running job: job_201412071622_0001
14/12/07 16:23:37 INFO mapred.JobClient:  map 0% reduce 0%
14/12/07 16:23:51 INFO mapred.JobClient:  map 100% reduce 0%
14/12/07 16:23:53 INFO mapred.JobClient: Job complete: job_201412071622_0001
14/12/07 16:23:53 INFO mapred.JobClient: Counters: 6
14/12/07 16:23:53 INFO mapred.JobClient:   Job Counters 
14/12/07 16:23:53 INFO mapred.JobClient:     Rack-local map tasks=1
14/12/07 16:23:53 INFO mapred.JobClient:     Launched map tasks=1
14/12/07 16:23:53 INFO mapred.JobClient:   FileSystemCounters
14/12/07 16:23:53 INFO mapred.JobClient:     HDFS_BYTES_READ=83935
14/12/07 16:23:53 INFO mapred.JobClient:     HDFS_BYTES_WRITTEN=77280
14/12/07 16:23:53 INFO mapred.JobClient:   Map-Reduce Framework
14/12/07 16:23:53 INFO mapred.JobClient:     Map input records=538
14/12/07 16:23:53 INFO mapred.JobClient:     Spilled Records=0
14/12/07 16:23:53 INFO vectorizer.SparseVectorsFromSequenceFiles: Creating Term Frequency Vectors
14/12/07 16:23:53 INFO vectorizer.DictionaryVectorizer: Creating dictionary from /data/tweets-vectors/tokenized-documents and saving at /data/tweets-vectors/wordcount
14/12/07 16:23:53 INFO input.FileInputFormat: Total input paths to process : 1
14/12/07 16:23:53 INFO mapred.JobClient: Running job: job_201412071622_0002
14/12/07 16:23:54 INFO mapred.JobClient:  map 0% reduce 0%
14/12/07 16:24:06 INFO mapred.JobClient:  map 100% reduce 0%
14/12/07 16:24:18 INFO mapred.JobClient:  map 100% reduce 100%
14/12/07 16:24:20 INFO mapred.JobClient: Job complete: job_201412071622_0002
14/12/07 16:24:20 INFO mapred.JobClient: Counters: 17
14/12/07 16:24:20 INFO mapred.JobClient:   Job Counters 
14/12/07 16:24:20 INFO mapred.JobClient:     Launched reduce tasks=1
14/12/07 16:24:20 INFO mapred.JobClient:     Launched map tasks=1
14/12/07 16:24:20 INFO mapred.JobClient:     Data-local map tasks=1
14/12/07 16:24:20 INFO mapred.JobClient:   FileSystemCounters
14/12/07 16:24:20 INFO mapred.JobClient:     FILE_BYTES_READ=56231
14/12/07 16:24:20 INFO mapred.JobClient:     HDFS_BYTES_READ=77280
14/12/07 16:24:20 INFO mapred.JobClient:     FILE_BYTES_WRITTEN=112494
14/12/07 16:24:20 INFO mapred.JobClient:     HDFS_BYTES_WRITTEN=24163
14/12/07 16:24:20 INFO mapred.JobClient:   Map-Reduce Framework
14/12/07 16:24:20 INFO mapred.JobClient:     Reduce input groups=0
14/12/07 16:24:20 INFO mapred.JobClient:     Combine output records=3225
14/12/07 16:24:20 INFO mapred.JobClient:     Map input records=538
14/12/07 16:24:20 INFO mapred.JobClient:     Reduce shuffle bytes=0
14/12/07 16:24:20 INFO mapred.JobClient:     Reduce output records=0
14/12/07 16:24:20 INFO mapred.JobClient:     Spilled Records=6450
14/12/07 16:24:20 INFO mapred.JobClient:     Map output bytes=119239
14/12/07 16:24:20 INFO mapred.JobClient:     Combine input records=8333
14/12/07 16:24:20 INFO mapred.JobClient:     Map output records=8333
14/12/07 16:24:20 INFO mapred.JobClient:     Reduce input records=3225
14/12/07 16:24:20 INFO input.FileInputFormat: Total input paths to process : 1
14/12/07 16:24:21 INFO mapred.JobClient: Running job: job_201412071622_0003
14/12/07 16:24:22 INFO mapred.JobClient:  map 0% reduce 0%
14/12/07 16:24:33 INFO mapred.JobClient:  map 100% reduce 0%
14/12/07 16:24:45 INFO mapred.JobClient:  map 100% reduce 100%
14/12/07 16:24:47 INFO mapred.JobClient: Job complete: job_201412071622_0003
14/12/07 16:24:47 INFO mapred.JobClient: Counters: 17
14/12/07 16:24:47 INFO mapred.JobClient:   Job Counters 
14/12/07 16:24:47 INFO mapred.JobClient:     Launched reduce tasks=1
14/12/07 16:24:47 INFO mapred.JobClient:     Launched map tasks=1
14/12/07 16:24:47 INFO mapred.JobClient:     Data-local map tasks=1
14/12/07 16:24:47 INFO mapred.JobClient:   FileSystemCounters
14/12/07 16:24:47 INFO mapred.JobClient:     FILE_BYTES_READ=93348
14/12/07 16:24:47 INFO mapred.JobClient:     HDFS_BYTES_READ=77280
14/12/07 16:24:47 INFO mapred.JobClient:     FILE_BYTES_WRITTEN=146668
14/12/07 16:24:47 INFO mapred.JobClient:     HDFS_BYTES_WRITTEN=77423
14/12/07 16:24:47 INFO mapred.JobClient:   Map-Reduce Framework
14/12/07 16:24:47 INFO mapred.JobClient:     Reduce input groups=0
14/12/07 16:24:47 INFO mapred.JobClient:     Combine output records=0
14/12/07 16:24:47 INFO mapred.JobClient:     Map input records=538
14/12/07 16:24:47 INFO mapred.JobClient:     Reduce shuffle bytes=0
14/12/07 16:24:47 INFO mapred.JobClient:     Reduce output records=0
14/12/07 16:24:47 INFO mapred.JobClient:     Spilled Records=1076
14/12/07 16:24:47 INFO mapred.JobClient:     Map output bytes=72167
14/12/07 16:24:47 INFO mapred.JobClient:     Combine input records=0
14/12/07 16:24:47 INFO mapred.JobClient:     Map output records=538
14/12/07 16:24:47 INFO mapred.JobClient:     Reduce input records=538
14/12/07 16:24:47 INFO input.FileInputFormat: Total input paths to process : 1
14/12/07 16:24:48 INFO mapred.JobClient: Running job: job_201412071622_0004
14/12/07 16:24:49 INFO mapred.JobClient:  map 0% reduce 0%
14/12/07 16:25:00 INFO mapred.JobClient:  map 100% reduce 0%
14/12/07 16:25:12 INFO mapred.JobClient:  map 100% reduce 100%
14/12/07 16:25:14 INFO mapred.JobClient: Job complete: job_201412071622_0004
14/12/07 16:25:14 INFO mapred.JobClient: Counters: 17
14/12/07 16:25:14 INFO mapred.JobClient:   Job Counters 
14/12/07 16:25:14 INFO mapred.JobClient:     Launched reduce tasks=1
14/12/07 16:25:14 INFO mapred.JobClient:     Rack-local map tasks=1
14/12/07 16:25:14 INFO mapred.JobClient:     Launched map tasks=1
14/12/07 16:25:14 INFO mapred.JobClient:   FileSystemCounters
14/12/07 16:25:14 INFO mapred.JobClient:     FILE_BYTES_READ=73709
14/12/07 16:25:14 INFO mapred.JobClient:     HDFS_BYTES_READ=77423
14/12/07 16:25:14 INFO mapred.JobClient:     FILE_BYTES_WRITTEN=147450
14/12/07 16:25:14 INFO mapred.JobClient:     HDFS_BYTES_WRITTEN=77423
14/12/07 16:25:14 INFO mapred.JobClient:   Map-Reduce Framework
14/12/07 16:25:14 INFO mapred.JobClient:     Reduce input groups=0
14/12/07 16:25:14 INFO mapred.JobClient:     Combine output records=0
14/12/07 16:25:14 INFO mapred.JobClient:     Map input records=512
14/12/07 16:25:14 INFO mapred.JobClient:     Reduce shuffle bytes=0
14/12/07 16:25:14 INFO mapred.JobClient:     Reduce output records=0
14/12/07 16:25:14 INFO mapred.JobClient:     Spilled Records=1024
14/12/07 16:25:14 INFO mapred.JobClient:     Map output bytes=72517
14/12/07 16:25:14 INFO mapred.JobClient:     Combine input records=0
14/12/07 16:25:14 INFO mapred.JobClient:     Map output records=512
14/12/07 16:25:14 INFO mapred.JobClient:     Reduce input records=512
14/12/07 16:25:14 INFO common.HadoopUtil: Deleting /data/tweets-vectors/partial-vectors-0
14/12/07 16:25:14 INFO vectorizer.SparseVectorsFromSequenceFiles: Calculating IDF
14/12/07 16:25:14 INFO input.FileInputFormat: Total input paths to process : 1
14/12/07 16:25:17 INFO mapred.JobClient: Running job: job_201412071622_0005
14/12/07 16:25:18 INFO mapred.JobClient:  map 0% reduce 0%
14/12/07 16:25:30 INFO mapred.JobClient:  map 100% reduce 0%
14/12/07 16:25:42 INFO mapred.JobClient:  map 100% reduce 100%
14/12/07 16:25:44 INFO mapred.JobClient: Job complete: job_201412071622_0005
14/12/07 16:25:44 INFO mapred.JobClient: Counters: 17
14/12/07 16:25:44 INFO mapred.JobClient:   Job Counters 
14/12/07 16:25:44 INFO mapred.JobClient:     Launched reduce tasks=1
14/12/07 16:25:44 INFO mapred.JobClient:     Launched map tasks=1
14/12/07 16:25:44 INFO mapred.JobClient:     Data-local map tasks=1
14/12/07 16:25:44 INFO mapred.JobClient:   FileSystemCounters
14/12/07 16:25:44 INFO mapred.JobClient:     FILE_BYTES_READ=14916
14/12/07 16:25:44 INFO mapred.JobClient:     HDFS_BYTES_READ=77423
14/12/07 16:25:44 INFO mapred.JobClient:     FILE_BYTES_WRITTEN=29864
14/12/07 16:25:44 INFO mapred.JobClient:     HDFS_BYTES_WRITTEN=21593
14/12/07 16:25:44 INFO mapred.JobClient:   Map-Reduce Framework
14/12/07 16:25:44 INFO mapred.JobClient:     Reduce input groups=0
14/12/07 16:25:44 INFO mapred.JobClient:     Combine output records=1065
14/12/07 16:25:44 INFO mapred.JobClient:     Map input records=512
14/12/07 16:25:44 INFO mapred.JobClient:     Reduce shuffle bytes=0
14/12/07 16:25:44 INFO mapred.JobClient:     Reduce output records=0
14/12/07 16:25:44 INFO mapred.JobClient:     Spilled Records=2130
14/12/07 16:25:44 INFO mapred.JobClient:     Map output bytes=75444
14/12/07 16:25:44 INFO mapred.JobClient:     Combine input records=6287
14/12/07 16:25:44 INFO mapred.JobClient:     Map output records=6287
14/12/07 16:25:44 INFO mapred.JobClient:     Reduce input records=1065
14/12/07 16:25:44 INFO vectorizer.SparseVectorsFromSequenceFiles: Pruning
14/12/07 16:25:44 INFO input.FileInputFormat: Total input paths to process : 1
14/12/07 16:25:45 INFO mapred.JobClient: Running job: job_201412071622_0006
14/12/07 16:25:46 INFO mapred.JobClient:  map 0% reduce 0%
14/12/07 16:25:57 INFO mapred.JobClient:  map 100% reduce 0%
14/12/07 16:26:09 INFO mapred.JobClient:  map 100% reduce 100%
14/12/07 16:26:11 INFO mapred.JobClient: Job complete: job_201412071622_0006
14/12/07 16:26:11 INFO mapred.JobClient: Counters: 17
14/12/07 16:26:11 INFO mapred.JobClient:   Job Counters 
14/12/07 16:26:11 INFO mapred.JobClient:     Launched reduce tasks=1
14/12/07 16:26:11 INFO mapred.JobClient:     Rack-local map tasks=1
14/12/07 16:26:11 INFO mapred.JobClient:     Launched map tasks=1
14/12/07 16:26:11 INFO mapred.JobClient:   FileSystemCounters
14/12/07 16:26:11 INFO mapred.JobClient:     FILE_BYTES_READ=38214
14/12/07 16:26:11 INFO mapred.JobClient:     HDFS_BYTES_READ=77423
14/12/07 16:26:11 INFO mapred.JobClient:     FILE_BYTES_WRITTEN=32946
14/12/07 16:26:11 INFO mapred.JobClient:     HDFS_BYTES_WRITTEN=77423
14/12/07 16:26:11 INFO mapred.JobClient:   Map-Reduce Framework
14/12/07 16:26:11 INFO mapred.JobClient:     Reduce input groups=0
14/12/07 16:26:11 INFO mapred.JobClient:     Combine output records=0
14/12/07 16:26:11 INFO mapred.JobClient:     Map input records=512
14/12/07 16:26:11 INFO mapred.JobClient:     Reduce shuffle bytes=0
14/12/07 16:26:11 INFO mapred.JobClient:     Reduce output records=0
14/12/07 16:26:11 INFO mapred.JobClient:     Spilled Records=1024
14/12/07 16:26:11 INFO mapred.JobClient:     Map output bytes=72517
14/12/07 16:26:11 INFO mapred.JobClient:     Combine input records=0
14/12/07 16:26:11 INFO mapred.JobClient:     Map output records=512
14/12/07 16:26:11 INFO mapred.JobClient:     Reduce input records=512
14/12/07 16:26:11 INFO input.FileInputFormat: Total input paths to process : 1
14/12/07 16:26:12 INFO mapred.JobClient: Running job: job_201412071622_0007
14/12/07 16:26:13 INFO mapred.JobClient:  map 0% reduce 0%
14/12/07 16:26:25 INFO mapred.JobClient:  map 100% reduce 0%
14/12/07 16:26:37 INFO mapred.JobClient:  map 100% reduce 100%
14/12/07 16:26:39 INFO mapred.JobClient: Job complete: job_201412071622_0007
14/12/07 16:26:39 INFO mapred.JobClient: Counters: 17
14/12/07 16:26:39 INFO mapred.JobClient:   Job Counters 
14/12/07 16:26:39 INFO mapred.JobClient:     Launched reduce tasks=1
14/12/07 16:26:39 INFO mapred.JobClient:     Launched map tasks=1
14/12/07 16:26:39 INFO mapred.JobClient:     Data-local map tasks=1
14/12/07 16:26:39 INFO mapred.JobClient:   FileSystemCounters
14/12/07 16:26:39 INFO mapred.JobClient:     FILE_BYTES_READ=73709
14/12/07 16:26:39 INFO mapred.JobClient:     HDFS_BYTES_READ=77423
14/12/07 16:26:39 INFO mapred.JobClient:     FILE_BYTES_WRITTEN=147450
14/12/07 16:26:39 INFO mapred.JobClient:     HDFS_BYTES_WRITTEN=77423
14/12/07 16:26:39 INFO mapred.JobClient:   Map-Reduce Framework
14/12/07 16:26:39 INFO mapred.JobClient:     Reduce input groups=0
14/12/07 16:26:39 INFO mapred.JobClient:     Combine output records=0
14/12/07 16:26:39 INFO mapred.JobClient:     Map input records=512
14/12/07 16:26:39 INFO mapred.JobClient:     Reduce shuffle bytes=0
14/12/07 16:26:39 INFO mapred.JobClient:     Reduce output records=0
14/12/07 16:26:39 INFO mapred.JobClient:     Spilled Records=1024
14/12/07 16:26:39 INFO mapred.JobClient:     Map output bytes=72517
14/12/07 16:26:39 INFO mapred.JobClient:     Combine input records=0
14/12/07 16:26:39 INFO mapred.JobClient:     Map output records=512
14/12/07 16:26:39 INFO mapred.JobClient:     Reduce input records=512
14/12/07 16:26:39 INFO common.HadoopUtil: Deleting /data/tweets-vectors/tf-vectors-partial
14/12/07 16:26:39 INFO common.HadoopUtil: Deleting /data/tweets-vectors/tf-vectors-toprune
14/12/07 16:26:39 INFO input.FileInputFormat: Total input paths to process : 1
14/12/07 16:26:40 INFO mapred.JobClient: Running job: job_201412071622_0008
14/12/07 16:26:41 INFO mapred.JobClient:  map 0% reduce 0%
14/12/07 16:26:52 INFO mapred.JobClient:  map 100% reduce 0%
14/12/07 16:27:04 INFO mapred.JobClient:  map 100% reduce 100%
14/12/07 16:27:06 INFO mapred.JobClient: Job complete: job_201412071622_0008
14/12/07 16:27:06 INFO mapred.JobClient: Counters: 17
14/12/07 16:27:06 INFO mapred.JobClient:   Job Counters 
14/12/07 16:27:06 INFO mapred.JobClient:     Launched reduce tasks=1
14/12/07 16:27:06 INFO mapred.JobClient:     Rack-local map tasks=1
14/12/07 16:27:06 INFO mapred.JobClient:     Launched map tasks=1
14/12/07 16:27:06 INFO mapred.JobClient:   FileSystemCounters
14/12/07 16:27:06 INFO mapred.JobClient:     FILE_BYTES_READ=95462
14/12/07 16:27:06 INFO mapred.JobClient:     HDFS_BYTES_READ=77423
14/12/07 16:27:06 INFO mapred.JobClient:     FILE_BYTES_WRITTEN=147450
14/12/07 16:27:06 INFO mapred.JobClient:     HDFS_BYTES_WRITTEN=77423
14/12/07 16:27:06 INFO mapred.JobClient:   Map-Reduce Framework
14/12/07 16:27:06 INFO mapred.JobClient:     Reduce input groups=0
14/12/07 16:27:06 INFO mapred.JobClient:     Combine output records=0
14/12/07 16:27:06 INFO mapred.JobClient:     Map input records=512
14/12/07 16:27:06 INFO mapred.JobClient:     Reduce shuffle bytes=0
14/12/07 16:27:06 INFO mapred.JobClient:     Reduce output records=0
14/12/07 16:27:06 INFO mapred.JobClient:     Spilled Records=1024
14/12/07 16:27:06 INFO mapred.JobClient:     Map output bytes=72517
14/12/07 16:27:06 INFO mapred.JobClient:     Combine input records=0
14/12/07 16:27:06 INFO mapred.JobClient:     Map output records=512
14/12/07 16:27:06 INFO mapred.JobClient:     Reduce input records=512
14/12/07 16:27:06 INFO input.FileInputFormat: Total input paths to process : 1
14/12/07 16:27:07 INFO mapred.JobClient: Running job: job_201412071622_0009
14/12/07 16:27:08 INFO mapred.JobClient:  map 0% reduce 0%
14/12/07 16:27:19 INFO mapred.JobClient:  map 100% reduce 0%
14/12/07 16:27:31 INFO mapred.JobClient:  map 100% reduce 100%
14/12/07 16:27:33 INFO mapred.JobClient: Job complete: job_201412071622_0009
14/12/07 16:27:33 INFO mapred.JobClient: Counters: 17
14/12/07 16:27:33 INFO mapred.JobClient:   Job Counters 
14/12/07 16:27:33 INFO mapred.JobClient:     Launched reduce tasks=1
14/12/07 16:27:33 INFO mapred.JobClient:     Rack-local map tasks=1
14/12/07 16:27:33 INFO mapred.JobClient:     Launched map tasks=1
14/12/07 16:27:33 INFO mapred.JobClient:   FileSystemCounters
14/12/07 16:27:33 INFO mapred.JobClient:     FILE_BYTES_READ=73709
14/12/07 16:27:33 INFO mapred.JobClient:     HDFS_BYTES_READ=77423
14/12/07 16:27:33 INFO mapred.JobClient:     FILE_BYTES_WRITTEN=147450
14/12/07 16:27:33 INFO mapred.JobClient:     HDFS_BYTES_WRITTEN=77423
14/12/07 16:27:33 INFO mapred.JobClient:   Map-Reduce Framework
14/12/07 16:27:33 INFO mapred.JobClient:     Reduce input groups=0
14/12/07 16:27:33 INFO mapred.JobClient:     Combine output records=0
14/12/07 16:27:33 INFO mapred.JobClient:     Map input records=512
14/12/07 16:27:33 INFO mapred.JobClient:     Reduce shuffle bytes=0
14/12/07 16:27:33 INFO mapred.JobClient:     Reduce output records=0
14/12/07 16:27:33 INFO mapred.JobClient:     Spilled Records=1024
14/12/07 16:27:33 INFO mapred.JobClient:     Map output bytes=72517
14/12/07 16:27:33 INFO mapred.JobClient:     Combine input records=0
14/12/07 16:27:33 INFO mapred.JobClient:     Map output records=512
14/12/07 16:27:33 INFO mapred.JobClient:     Reduce input records=512
14/12/07 16:27:33 INFO common.HadoopUtil: Deleting /data/tweets-vectors/partial-vectors-0
14/12/07 16:27:33 INFO driver.MahoutDriver: Program took 238681 ms (Minutes: 3.9780166666666665)
-------list directory tweets-vectors ---
Found 7 items
drwxr-xr-x   - balasesh supergroup          0 2014-12-07 16:25 /data/tweets-vectors/df-count
-rw-r--r--   1 balasesh supergroup      19866 2014-12-07 16:24 /data/tweets-vectors/dictionary.file-0
-rw-r--r--   1 balasesh supergroup      21573 2014-12-07 16:25 /data/tweets-vectors/frequency.file-0
drwxr-xr-x   - balasesh supergroup          0 2014-12-07 16:26 /data/tweets-vectors/tf-vectors
drwxr-xr-x   - balasesh supergroup          0 2014-12-07 16:27 /data/tweets-vectors/tfidf-vectors
drwxr-xr-x   - balasesh supergroup          0 2014-12-07 16:23 /data/tweets-vectors/tokenized-documents
drwxr-xr-x   - balasesh supergroup          0 2014-12-07 16:24 /data/tweets-vectors/wordcount
 ------Using mahout to splits the sets into two sets: traing and testing sets ---
CLASSPATH with MAHOUT=:/util/mahout/mahout-distribution-0.8/src/conf
MAHOUT_LOCAL is not set; adding HADOOP_CONF_DIR to classpath.
CLASSPATH with HADOOP=:/util/mahout/mahout-distribution-0.8/src/conf:/ifs/user/balasesh/assgn4/mahout/config
CLASSPATH with JAVA=:/util/mahout/mahout-distribution-0.8/src/conf:/ifs/user/balasesh/assgn4/mahout/config:/util/java/jdk1.6.0_22//lib/tools.jar
Running on hadoop, using /util/hadoop/hadoop-0.20.1/bin/hadoop and HADOOP_CONF_DIR=/ifs/user/balasesh/assgn4/mahout/config
MAHOUT-JOB: /util/mahout/mahout-distribution-0.8/examples/target/mahout-examples-0.8-job.jar
14/12/07 16:27:38 WARN driver.MahoutDriver: No split.props found on classpath, will use command-line arguments only
14/12/07 16:27:38 INFO common.AbstractJob: Command line arguments: {--endPhase=[2147483647], --input=[/data/tweets-vectors/tfidf-vectors], --method=[sequential], --overwrite=null, --randomSelectionPct=[40], --sequenceFiles=null, --startPhase=[0], --tempDir=[temp], --testOutput=[/data/test-vectors], --trainingOutput=[/data/train-vectors]}
14/12/07 16:27:38 INFO utils.SplitInput: part-r-00000 has 434 lines
14/12/07 16:27:38 INFO utils.SplitInput: part-r-00000 test split size is 174 based on random selection percentage 40
14/12/07 16:27:38 INFO util.NativeCodeLoader: Loaded the native-hadoop library
14/12/07 16:27:38 INFO zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
14/12/07 16:27:38 INFO compress.CodecPool: Got brand-new compressor
14/12/07 16:27:38 INFO compress.CodecPool: Got brand-new compressor
14/12/07 16:27:39 INFO utils.SplitInput: file: part-r-00000, input: 434 train: 338, test: 174 starting at 0
14/12/07 16:27:39 INFO driver.MahoutDriver: Program took 702 ms (Minutes: 0.0117)
-------Train the classifier on training set---
CLASSPATH with MAHOUT=:/util/mahout/mahout-distribution-0.8/src/conf
MAHOUT_LOCAL is not set; adding HADOOP_CONF_DIR to classpath.
CLASSPATH with HADOOP=:/util/mahout/mahout-distribution-0.8/src/conf:/ifs/user/balasesh/assgn4/mahout/config
CLASSPATH with JAVA=:/util/mahout/mahout-distribution-0.8/src/conf:/ifs/user/balasesh/assgn4/mahout/config:/util/java/jdk1.6.0_22//lib/tools.jar
Running on hadoop, using /util/hadoop/hadoop-0.20.1/bin/hadoop and HADOOP_CONF_DIR=/ifs/user/balasesh/assgn4/mahout/config
MAHOUT-JOB: /util/mahout/mahout-distribution-0.8/examples/target/mahout-examples-0.8-job.jar
14/12/07 16:27:43 WARN driver.MahoutDriver: No trainnb.props found on classpath, will use command-line arguments only
14/12/07 16:27:43 INFO common.AbstractJob: Command line arguments: {--alphaI=[1.0], --endPhase=[2147483647], --extractLabels=null, --input=[/data/train-vectors], --labelIndex=[labelindex], --output=[model], --overwrite=null, --startPhase=[0], --tempDir=[temp], --trainComplementary=null}
14/12/07 16:27:43 INFO util.NativeCodeLoader: Loaded the native-hadoop library
14/12/07 16:27:43 INFO zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
14/12/07 16:27:43 INFO compress.CodecPool: Got brand-new decompressor
14/12/07 16:27:44 INFO input.FileInputFormat: Total input paths to process : 1
14/12/07 16:27:45 INFO mapred.JobClient: Running job: job_201412071622_0010
14/12/07 16:27:46 INFO mapred.JobClient:  map 0% reduce 0%
14/12/07 16:27:58 INFO mapred.JobClient:  map 100% reduce 0%
14/12/07 16:28:10 INFO mapred.JobClient:  map 100% reduce 100%
14/12/07 16:28:12 INFO mapred.JobClient: Job complete: job_201412071622_0010
14/12/07 16:28:12 INFO mapred.JobClient: Counters: 17
14/12/07 16:28:12 INFO mapred.JobClient:   Job Counters 
14/12/07 16:28:12 INFO mapred.JobClient:     Launched reduce tasks=1
14/12/07 16:28:12 INFO mapred.JobClient:     Launched map tasks=1
14/12/07 16:28:12 INFO mapred.JobClient:     Data-local map tasks=1
14/12/07 16:28:12 INFO mapred.JobClient:   FileSystemCounters
14/12/07 16:28:12 INFO mapred.JobClient:     FILE_BYTES_READ=5927
14/12/07 16:28:12 INFO mapred.JobClient:     HDFS_BYTES_READ=45631
14/12/07 16:28:12 INFO mapred.JobClient:     FILE_BYTES_WRITTEN=11432
14/12/07 16:28:12 INFO mapred.JobClient:     HDFS_BYTES_WRITTEN=15019
14/12/07 16:28:12 INFO mapred.JobClient:   Map-Reduce Framework
14/12/07 16:28:12 INFO mapred.JobClient:     Reduce input groups=0
14/12/07 16:28:12 INFO mapred.JobClient:     Combine output records=7
14/12/07 16:28:12 INFO mapred.JobClient:     Map input records=338
14/12/07 16:28:12 INFO mapred.JobClient:     Reduce shuffle bytes=0
14/12/07 16:28:12 INFO mapred.JobClient:     Reduce output records=0
14/12/07 16:28:12 INFO mapred.JobClient:     Spilled Records=14
14/12/07 16:28:12 INFO mapred.JobClient:     Map output bytes=40108
14/12/07 16:28:12 INFO mapred.JobClient:     Combine input records=338
14/12/07 16:28:12 INFO mapred.JobClient:     Map output records=338
14/12/07 16:28:12 INFO mapred.JobClient:     Reduce input records=7
14/12/07 16:28:12 INFO input.FileInputFormat: Total input paths to process : 1
14/12/07 16:28:12 INFO mapred.JobClient: Running job: job_201412071622_0011
14/12/07 16:28:13 INFO mapred.JobClient:  map 0% reduce 0%
14/12/07 16:28:24 INFO mapred.JobClient:  map 100% reduce 0%
14/12/07 16:28:37 INFO mapred.JobClient:  map 100% reduce 100%
14/12/07 16:28:39 INFO mapred.JobClient: Job complete: job_201412071622_0011
14/12/07 16:28:39 INFO mapred.JobClient: Counters: 17
14/12/07 16:28:39 INFO mapred.JobClient:   Job Counters 
14/12/07 16:28:39 INFO mapred.JobClient:     Launched reduce tasks=1
14/12/07 16:28:39 INFO mapred.JobClient:     Rack-local map tasks=1
14/12/07 16:28:39 INFO mapred.JobClient:     Launched map tasks=1
14/12/07 16:28:39 INFO mapred.JobClient:   FileSystemCounters
14/12/07 16:28:39 INFO mapred.JobClient:     FILE_BYTES_READ=3549
14/12/07 16:28:39 INFO mapred.JobClient:     HDFS_BYTES_READ=15019
14/12/07 16:28:39 INFO mapred.JobClient:     FILE_BYTES_WRITTEN=7122
14/12/07 16:28:39 INFO mapred.JobClient:     HDFS_BYTES_WRITTEN=9654
14/12/07 16:28:39 INFO mapred.JobClient:   Map-Reduce Framework
14/12/07 16:28:39 INFO mapred.JobClient:     Reduce input groups=0
14/12/07 16:28:39 INFO mapred.JobClient:     Combine output records=2
14/12/07 16:28:39 INFO mapred.JobClient:     Map input records=7
14/12/07 16:28:39 INFO mapred.JobClient:     Reduce shuffle bytes=0
14/12/07 16:28:39 INFO mapred.JobClient:     Reduce output records=0
14/12/07 16:28:39 INFO mapred.JobClient:     Spilled Records=4
14/12/07 16:28:39 INFO mapred.JobClient:     Map output bytes=9528
14/12/07 16:28:39 INFO mapred.JobClient:     Combine input records=2
14/12/07 16:28:39 INFO mapred.JobClient:     Map output records=2
14/12/07 16:28:39 INFO mapred.JobClient:     Reduce input records=2
14/12/07 16:28:39 INFO driver.MahoutDriver: Program took 55625 ms (Minutes: 0.9270833333333334)
---------See what's in HDFS ------
Found 3 items
drwxr-xr-x   - balasesh supergroup          0 2014-12-07 16:27 /data
drwxr-xr-x   - balasesh supergroup          0 2014-12-07 16:23 /scratch
drwxr-xr-x   - balasesh supergroup          0 2014-12-07 16:27 /user
-------To test the classifier is working properly on training set ---
CLASSPATH with MAHOUT=:/util/mahout/mahout-distribution-0.8/src/conf
MAHOUT_LOCAL is not set; adding HADOOP_CONF_DIR to classpath.
CLASSPATH with HADOOP=:/util/mahout/mahout-distribution-0.8/src/conf:/ifs/user/balasesh/assgn4/mahout/config
CLASSPATH with JAVA=:/util/mahout/mahout-distribution-0.8/src/conf:/ifs/user/balasesh/assgn4/mahout/config:/util/java/jdk1.6.0_22//lib/tools.jar
Running on hadoop, using /util/hadoop/hadoop-0.20.1/bin/hadoop and HADOOP_CONF_DIR=/ifs/user/balasesh/assgn4/mahout/config
MAHOUT-JOB: /util/mahout/mahout-distribution-0.8/examples/target/mahout-examples-0.8-job.jar
14/12/07 16:28:44 WARN driver.MahoutDriver: No testnb.props found on classpath, will use command-line arguments only
14/12/07 16:28:44 INFO common.AbstractJob: Command line arguments: {--endPhase=[2147483647], --input=[/data/train-vectors], --labelIndex=[labelindex], --model=[model], --output=[/data/tweets-testing], --overwrite=null, --startPhase=[0], --tempDir=[temp], --testComplementary=null}
14/12/07 16:28:45 INFO input.FileInputFormat: Total input paths to process : 1
14/12/07 16:28:45 INFO mapred.JobClient: Running job: job_201412071622_0012
14/12/07 16:28:46 INFO mapred.JobClient:  map 0% reduce 0%
14/12/07 16:29:00 INFO mapred.JobClient:  map 100% reduce 0%
14/12/07 16:29:02 INFO mapred.JobClient: Job complete: job_201412071622_0012
14/12/07 16:29:02 INFO mapred.JobClient: Counters: 7
14/12/07 16:29:02 INFO mapred.JobClient:   Job Counters 
14/12/07 16:29:02 INFO mapred.JobClient:     Launched map tasks=1
14/12/07 16:29:02 INFO mapred.JobClient:     Data-local map tasks=1
14/12/07 16:29:02 INFO mapred.JobClient:   FileSystemCounters
14/12/07 16:29:02 INFO mapred.JobClient:     FILE_BYTES_READ=24556
14/12/07 16:29:02 INFO mapred.JobClient:     HDFS_BYTES_READ=45631
14/12/07 16:29:02 INFO mapred.JobClient:     HDFS_BYTES_WRITTEN=24620
14/12/07 16:29:02 INFO mapred.JobClient:   Map-Reduce Framework
14/12/07 16:29:02 INFO mapred.JobClient:     Map input records=338
14/12/07 16:29:02 INFO mapred.JobClient:     Spilled Records=0
14/12/07 16:29:02 INFO test.TestNaiveBayesDriver: Complementary Results: 
=======================================================
Summary
-------------------------------------------------------
Correctly Classified Instances          :        330	   97.6331%
Incorrectly Classified Instances        :          8	    2.3669%
Total Classified Instances              :        338

=======================================================
Confusion Matrix
-------------------------------------------------------
a    	b    	c    	d    	e    	f    	g    	<--Classified as
64   	0    	0    	0    	0    	0    	0    	 |  64    	a     = apparel
0    	39   	0    	1    	0    	0    	0    	 |  40    	b     = art
0    	0    	28   	0    	1    	0    	0    	 |  29    	c     = camera
1    	0    	0    	33   	0    	0    	0    	 |  34    	d     = event
0    	0    	0    	0    	34   	0    	0    	 |  34    	e     = health
1    	1    	0    	0    	0    	33   	1    	 |  36    	f     = home
0    	1    	1    	0    	0    	0    	99   	 |  101   	g     = tech

=======================================================
Statistics
-------------------------------------------------------
Kappa                                       0.9221
Accuracy                                   97.6331%
Reliability                                85.0996%
Reliability (standard deviation)            0.3448

14/12/07 16:29:02 INFO driver.MahoutDriver: Program took 18469 ms (Minutes: 0.3078166666666667)
------- To test the classifier is working properly on testing set ---
CLASSPATH with MAHOUT=:/util/mahout/mahout-distribution-0.8/src/conf
MAHOUT_LOCAL is not set; adding HADOOP_CONF_DIR to classpath.
CLASSPATH with HADOOP=:/util/mahout/mahout-distribution-0.8/src/conf:/ifs/user/balasesh/assgn4/mahout/config
CLASSPATH with JAVA=:/util/mahout/mahout-distribution-0.8/src/conf:/ifs/user/balasesh/assgn4/mahout/config:/util/java/jdk1.6.0_22//lib/tools.jar
Running on hadoop, using /util/hadoop/hadoop-0.20.1/bin/hadoop and HADOOP_CONF_DIR=/ifs/user/balasesh/assgn4/mahout/config
MAHOUT-JOB: /util/mahout/mahout-distribution-0.8/examples/target/mahout-examples-0.8-job.jar
14/12/07 16:29:07 WARN driver.MahoutDriver: No testnb.props found on classpath, will use command-line arguments only
14/12/07 16:29:07 INFO common.AbstractJob: Command line arguments: {--endPhase=[2147483647], --input=[/data/test-vectors], --labelIndex=[labelindex], --model=[model], --output=[tweets-testing], --overwrite=null, --startPhase=[0], --tempDir=[temp], --testComplementary=null}
14/12/07 16:29:08 INFO input.FileInputFormat: Total input paths to process : 1
14/12/07 16:29:08 INFO mapred.JobClient: Running job: job_201412071622_0013
14/12/07 16:29:09 INFO mapred.JobClient:  map 0% reduce 0%
14/12/07 16:29:24 INFO mapred.JobClient:  map 100% reduce 0%
14/12/07 16:29:26 INFO mapred.JobClient: Job complete: job_201412071622_0013
14/12/07 16:29:26 INFO mapred.JobClient: Counters: 7
14/12/07 16:29:26 INFO mapred.JobClient:   Job Counters 
14/12/07 16:29:26 INFO mapred.JobClient:     Launched map tasks=1
14/12/07 16:29:26 INFO mapred.JobClient:     Data-local map tasks=1
14/12/07 16:29:26 INFO mapred.JobClient:   FileSystemCounters
14/12/07 16:29:26 INFO mapred.JobClient:     FILE_BYTES_READ=24556
14/12/07 16:29:26 INFO mapred.JobClient:     HDFS_BYTES_READ=24170
14/12/07 16:29:26 INFO mapred.JobClient:     HDFS_BYTES_WRITTEN=12775
14/12/07 16:29:26 INFO mapred.JobClient:   Map-Reduce Framework
14/12/07 16:29:26 INFO mapred.JobClient:     Map input records=174
14/12/07 16:29:26 INFO mapred.JobClient:     Spilled Records=0
14/12/07 16:29:26 INFO test.TestNaiveBayesDriver: Complementary Results: 
=======================================================
Summary
-------------------------------------------------------
Correctly Classified Instances          :        123	   70.6897%
Incorrectly Classified Instances        :         51	   29.3103%
Total Classified Instances              :        174

=======================================================
Confusion Matrix
-------------------------------------------------------
a    	b    	c    	d    	e    	f    	g    	<--Classified as
26   	4    	0    	0    	2    	1    	2    	 |  35    	a     = apparel
2    	17   	0    	3    	1    	0    	2    	 |  25    	b     = art
0    	0    	29   	1    	0    	1    	0    	 |  31    	c     = camera
1    	3    	0    	18   	4    	1    	0    	 |  27    	d     = event
3    	1    	1    	5    	9    	1    	1    	 |  21    	e     = health
2    	2    	1    	0    	2    	13   	1    	 |  21    	f     = home
0    	0    	1    	0    	0    	2    	11   	 |  14    	g     = tech

=======================================================
Statistics
-------------------------------------------------------
Kappa                                       0.5427
Accuracy                                   70.6897%
Reliability                                60.7293%
Reliability (standard deviation)            0.2848

14/12/07 16:29:26 INFO driver.MahoutDriver: Program took 19595 ms (Minutes: 0.32658333333333334)
stop jobtracker (mapred)
stopping jobtracker
d15n32: stopping tasktracker
d15n34: stopping tasktracker
stop dfs
stopping namenode
d15n34: stopping datanode
d15n32: stopping datanode
d15n32: stopping secondarynamenode
Clean up
Number of Hadoop nodes specified by user: 2
Received 2 nodes from PBS
Clean up node: d15n32
rm -rf /scratch/hadoop-balasesh/data /scratch/hadoop-balasesh/log
Clean up node: d15n34
rm -rf /scratch/hadoop-balasesh/data /scratch/hadoop-balasesh/log

